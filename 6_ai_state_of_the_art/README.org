#+TITLE:State of the Art of AI
#+AUTHOR: Marcus Birkenkrahe
#+Subtitle: Seminar on Artificial Intelligence
#+OPTIONS: toc:nil num:nil ^:nil
#+INFOJS_OPT: :view:info
* Machine learning
  After looking at the [[https://github.com/birkenkrahe/ai482/tree/main/4_ai_history][history of AI]], and some of the foundations of a
  dominant AI methodology ([[https://github.com/birkenkrahe/ai482/tree/main/5_ai_agents][intelligent agents]]), we need to take stock
  of what AI actually achieves today, and why it's such a hot
  topic. It turns out that most of the running AI applications
  ("production AI") is related to machine learning (ML), i.e. learning
  agents, especially supervised learning - recognizing (= classifying)
  known patterns learnt from big data samples. Ng's first definition
  of ML is Samuel's seminal 1959 definition ([[ng18][stanfordonline,
  2020]])[fn:1]:

  #+begin_quote
  Machine learning: field of study that gives computers the ability to
  learn without being explicitly programmed.
  #+end_quote

  Ng gives a list of supervised learning tasks that have successfully
  been addressed by machines using a simple I/O model [[https://youtu.be/tsPuVAMaADY?t=547][(Source:
  Stanford HAI 2020)]].

  | Input (A)     | Output (O)       | ML application     |
  |---------------+------------------+--------------------|
  | email         | spam? (0/1)      | spam filtering     |
  | ad, user info | click? (0/1)     | online advertising |
  | phone image   | scratched? (0/1) | visual inspection  |
  | audio         | text transcript  | speech recognition |

  In most of these, the AI only needs to classify the input as one of
  two kinds (0/1), e.g. in spam filtering: spam or not spam. Audio ML
  is more complicated, because it relies on understanding natural
  language.

* AI research-to-production gap

  In this video AI researcher Andrew Ng addresses three issues to
  explain why ML is not more successful in the real world ([[ng][Stanford
  HAI, 2020]]). Many academic research results are spectacular, but in
  real settings, e.g. hospitals, you don't find AI (except in
  embedded, i.e. invisible systems like cameras, sensors etc.).

  For details, see student session protocols. Here you find only
  technical glossary additions and stuff that was left out of the
  protocols.

** Small data

   Examples for [[https://youtu.be/tsPuVAMaADY?t=1054][small data algorithms]] include GANs and GPT-3.

   GANs stands for Generative Adversarial Network (cp. [[https://en.wikipedia.org/wiki/Generative_adversarial_network][Wikipedia]]),
   which is a game theoretical ML application where two neural
   networks learn by competing with each other. Originated
   in 2014. Here is a nice video introduction ([[serrano][Serrano, 2020]]).

   GPT-3 is the Generative Pre-trained Transformer 3 (cp. [[https://en.wikipedia.org/wiki/GPT-3][Wikipedia]])
   used especially in natural language processing (NLP), e.g. to
   simulate human language. Originated in 2020. Here is an example of
   such a simulated conversation between two GPT-3 trained AIs
   ([[soslow][Soslow, 2021]]).

** Generalization and robustness

   It doesn't seem to me as if this problem is well understood though
   the problem setting is clear: humans environments are too complex
   for using AI applications developed and tested in the lab.

   #+attr_html: :width 600px
   [[./img/xray.jpg]]

   /Image: an old X-ray machine (Source: [[vintage][vintage.es]])/

** Change management

   Change is a hugely complex issue, partly because of the generality
   of the concept, and partly because of the deep-seated knowledge
   that behavioral change is usually hard to bring about - the harder,
   the more established a behavior is. There is a hundred years of
   management literature alone written about it. And of course, almost
   all of the serious fiction literature of the world is about
   transformative, real change. Still, it is not clear to me if
   "change management" isn't an oxymoron.

*** A naive model

    [[./img/naive.png]]

    (Source: Society of competitive intelligence)

*** Ideal process model

    [[./img/accenture.png]]

    (Source: Accenture)

*** Building blocks

    [[./img/siemens.png]]

    (Source: SIEMENS)

*** Glossary

    * [[https://pubmed.ncbi.nlm.nih.gov/33375658/][Explainable AI?]] ([[xai][Linardatos et al, 2020]]) - XAI

      #+begin_quote
      The field of Explainable Artificial Intelligence (XAI) [...] is
      concerned with the development of new methods that explain and
      interpret machine learning models,
      #+end_quote

    * [[https://www.ey.com/en_gl/assurance/how-artificial-intelligence-will-transform-the-audit][AI Auditing?]] ([[boillet][Boillet, 2018]]) - Risk analysis

** Efficiency vs. resilience

   We didn't really do this topic justice, which is hot right now
   because of the pandemic: some argue that society needs to refocus
   from optimizing processes to identifying and building structures
   that can take pressure and survive crisis situations. This is not
   necessarily a contradiction - much depends on one's definitions of
   efficiency vs. resilience. I mentioned the origins of the Internet
   and packet switching technology as a prime example of resilient
   infrastructure design (cp. [[leiner][Leiner et al, 1997]]).

   Here is a modern attack on the "relentless pursuit of efficiency"
   by a computer scientist whose title says it all: "Engineers and
   economists prize efficiency, but nature favors resilience – lessons
   from Texas, COVID-19 and the 737 Max" ([[vardi][Vardi, 2021]]). In the
   comments, you find a few voices disagreeing with this simplistic
   setup. In computer science at least, both efficiency and resilience
   are important design criteria.

   I mentioned this curve from a 2009 article analysing resilience in
   the light of the 2008 global financial crisis ([[lietaer][Lietaer et al,
   2009]]). It is used to illustrate "Sustainability" as a function of
   "Diversity & Interconnectivity" - all of them difficult to measure
   and to separate from one another. The model assumes an analogy
   between systems in nature and man-made financial systems.

   #+begin_quote
   Image caption (A): Sustainability curve mapped between the two
   polarities of efficiency and resilience. Nature selects not for
   maximum of efficiency, but for an optimal balance between these two
   requirements. Notice that resilience is roughly two times more
   important than efficiency at the optimum. All natural eco-systems
   operate within a fairly narrow range on each side of the Optimum
   point called the “Window of Viability”. (Lietaer et al, 2009)
   #+end_quote

   [[./img/2009.png]]

   Specifically on deep learning, here's a recent article by [[deepl][Thompson
   (2021)]] that attacks deep learning research and production as
   non-sustainable in terms of energy expenditure. Similar arguments
   are being put forward against blockchain mining (cp. [[block][Sedlmeir et
   al, 2020]], for a systematic, scientific discussion)[fn:2].

** Full cycle of machine learning projects
   
   The image shows Ng's puzzle picture for machine learning. Coding is
   a small part of this picture. The Lyon College data science program
   is an attempt to capture many, if not all aspects of this picture,
   with different courses (like AI, and modeling), specializations
   (like business information systems, and TinyML), techniques (like
   Scrum) and tools (like R, and GitHub).

   [[./img/full.png]]

** Glossary

   Even when listening to a talk for a large audience (of experts -
   each of which is an expert in his or her tiny area of
   specialization), you come across a lot of technical terms and
   concepts. When watching such videos or reading blogs you should
   always be building your own glossary of terms. It will
   progressively make your reading faster and easier, and aid your
   understanding of state of the art publications.

*** To be Scientific or not to be Scientific

    Even today (2021), not only 10 years ago, as Ng claims, many
    scientists wouldn't call ML or AI especially scientific. The
    reason is that new areas, and especially interdisciplinary areas
    (like data science) are considered "under-theorized". I came
    across this label in an article on theoretical biology
    ([[quanta][Cepelewicz, 2020]]): apparently, biology does (so far) not have a
    proper concept of what an "individual" is. Some researchers from
    the Santa Fe institute for complexity science came up with a
    stochastic (mathematical) definition that allows to describe
    individuals as well as collections of individuals (like
    swarms). Personally, I don't find the theory very convincing at
    all, but the point is that even a science like biology (certainly
    a few hundred years old already) is still "under-theorized", does
    not have "enough" theory, which means that many problems cannot be
    described formally and therefore not be investigated
    systematically (except empirically, by making experiments,
    counting insect legs etc.).

    Computer science (and AI/ML as part of it), is in a similar
    situation. Ng's suggestion is not to push the theory, but approach
    it from a practical perspective, as an engineering science (like a
    craft with extra computing power).

*** Cloud and edge implementation

    [[https://www.tinyml.org/][TinyML]] - machine learning at low power on embedded devices. Here's
    an example that would've been sci-fi only a few years back:
    "Flying Microchips The Size Of A Sand Grain" ([[npr][Neuman, 2021]]).

    [[./img/tiny.png]]

    I've just about decided to invest some of my 2021-22 research
    money from the college into buying gear for TinyML experiments in
    class. It's not all that expensive (cause it's tiny) - [[https://www.arducam.com/raspberry-pi-pico-tensorflow-lite-micro-person-detection-arducam/][see "The
    Future of Machine Learning is Tiny"]] - and it might make some cool
    applications for the data science ML class[fn:3].

*** Design pattern

    [[https://www.tutorialspoint.com/design_pattern/design_pattern_overview.htm][Check out this tutorial]] for design patterns in software
    development. There is a good book on design patterns for
    self-study from HeadFirst Labs ([[pattern][Freeman et al, 2004]]).

    The image ([[pattern][Heer/Agrawala 2006]]) shows a system diagram of 21
    various software design patterns.

    [[./img/pattern_map.gif]]

*** Softmax model

    This is a logistic regression type model (here is a [[http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/][technical
    tutorial]]), which is common in ML because it performs a binary
    classification.

*** Hyperparameters

    Values to control the learning process - not derived during
    training. They depend on the model used. An example would be the
    number of layers of a deep learning neural network, which remain
    unchanged as part of the algorithmic model.

*** Bounding box

    Image processing tool ([[https://keymakr.com/blog/what-are-bounding-boxes/][explanation]]). Bounding boxes are a form of
    labelling image data by drawing a box around classifiable areas.

*** DevOps/MLOps

    The IBM definition of DevOps ([[ibm][Crawford, 2019]]):

    #+begin_quote
    "DevOps outlines a software development process and an
    organizational culture shift that speeds the delivery of higher
    quality software by automating and integrating the efforts of
    development and IT operations teams – two groups that
    traditionally practiced separately from each other, or in silos."
    #+end_quote

** Summary

   * AI experiences a proof-of-concept to production gap
   * This leads to delayed development and use
   * Challenges include: data, resilience, change
   * AI in practice/production favors debugging skills
   * AI should become an engineering discipline

** Further information
   
   Andrew Ng further outlines his ideas on healthcare in [[https://hai.stanford.edu/events/healthcares-ai-future-conversation-fei-fei-li-andrew-ng][this long
   panel discussion]]. Earlier this year, he launched a "campaign for
   data-centric" (instead of model/algorithm-centered) AI ([[press][Press,
   2021]]).
 

* References

  <<boillet>> Boillet J (Jul 20, 2018). How AI will transform the
  audit [video]. [[https://www.ey.com/en_gl/assurance/how-artificial-intelligence-will-transform-the-audit][Online: ey.com]].

  <<quanta>> Cepelewicz J (July 16, 2021). What Is an Individual?
  Biology Seeks Clues in Information Theory [Blog]. [[https://www.quantamagazine.org/what-is-an-individual-biology-seeks-clues-in-information-theory-20200716/][Online:
  quantamagazine.com.]]

  <<ibm>> Crawford A (2019). DevOps [website]. [[https://www.ibm.com/cloud/learn/devops-a-complete-guide][Online: ibm.com.]]

  <<freeman>> Freeman et al (2004). Head First Design
  Patterns. Sebastopol: O'Reilly. [[https://www.oreilly.com/library/view/head-first-design/0596007124/][Online: oreilly.com.]]

  <<pattern>> Heer J/Agrawala M (2006). Software Design Patterns for
  Information Visualization. In: IEEE Transactions on Visualization
  and Computer Graphics (TVCG), 12(5). [[http://vis.berkeley.edu/papers/infovis_design_patterns/][Online: berkeley.edu.]]

  <<leiner>> Leiner et al (1997). Brief History of the Internet. In:
  Comm. of the ACM Feb 1997. [[https://www.internetsociety.org/internet/history-internet/brief-history-internet/#f3][Online: internetsociety.org.]]

  <<lietaer>> Lietaer et al (2009). Options for Managing a Systemic
  Bank Crisis. In: Sapiens 2(1). [[https://journals.openedition.org/sapiens/747][Online: journals.openedition.org]].

  <<xai>> Linardatos et al (2020). Explainable AI: A Review of Machine
  Learning Interpretability Methods. In: Entropy 23(1).  [[https://pubmed.ncbi.nlm.nih.gov/33375658/][doi:
  10.3390/e23010018. PMID: 33375658; PMCID: PMC7824368]].

  Michael (May 5, 2021). Image Processing Techniques: What Are
  Bounding Boxes? [Blog]. [[https://keymakr.com/blog/what-are-bounding-boxes/][Online: keymakr.com]].

  <<vintage>> n.a.(3 Feb 2016). 15 Incredible Vintage Photos of People
  Getting X-Rays Over the Decades [website]. [[https://www.vintag.es/2016/02/incredible-vintage-photos-of-people.html][Online: vintage.es]].

  <<npr>> Neuman S (Sept 23, 2021). Flying Microchips The Size Of A
  Sand Grain Could Be Used For Population Surveillance [blog]. [[https://www.npr.org/2021/09/23/1040035430/flying-microchip-sand-grain-northwestern-winged][Online:
  npr.org]].

  <<press>> Press G (June 16, 2021). Andrew Ng Launches A Campaign For
  Data-Centric AI. [[https://www.forbes.com/sites/gilpress/2021/06/16/andrew-ng-launches-a-campaign-for-data-centric-ai/?sh=d11550874f57][Online: forbes.com]].

  <<block>> Sedlmeir et al (2020). The Energy Consumption of
  Blockchain Technology: Beyond Myth. In: Business & Information
  Systems Engineering 62:599-608. [[https://link.springer.com/article/10.1007/s12599-020-00656-x][Online: link.springer.com]].

  <<serrano>> Serrano L (May 5, 2020). A Friendly Introduction to
  Generative Adversarial Networks (GANs) [video]. [[https://youtu.be/8L11aMN5KY8][Online: youtube.com]].

  <<soslow>> Jack Soslow (Apr 13, 2021). Two AIs talk about becoming
  human. (GPT-3) [video]. [[https://youtu.be/jz78fSnBG0s][Online: youtube.com]].

  <<ng>> Stanford HAI (Sep 23, 2020). Andrew Ng: Bridging AI's
  Proof-of-Concept to Production Gap [video]. [[https://youtu.be/tsPuVAMaADY][Online: youtube.com]].

  <<stanford>> Stanford HAI (Apr 29, 2021). Healthcare's AI Future: A
   Conversation with Fei-Fei Li & Andrew Ng. [[https://hai.stanford.edu/events/healthcares-ai-future-conversation-fei-fei-li-andrew-ng][Online: stanford.edu]].

  <<ng18>> stanfordonline (Apr 17, 2020). Lecture 1 - Stanford CS229:
  Machine Learning - Andrew Ng (Autumn 2018) [video]. [[https://youtu.be/jGwO_UgTS7I?t=2180][Online:
  youtube.com]].

  <<deepl>> Thompson et al (24 Sep 2021). Deep Learning's Diminishing
  Returns. [[https://spectrum.ieee.org/deep-learning-computational-cost][Online: spectrum.ieee.org]].

  UFLDL Tutorial (n.d.) Softmax Regression [Website]. [[http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/][Online:
  ufldl.stanford.edu.]]

  <<vardi>> Vardi MY (May 18, 2021). "Engineers and economists prize
  efficiency, but nature favors resilience – lessons from Texas,
  COVID-19 and the 737 Max".

  Warden P (Feb 3, 2021). The Future of Machine Learning is Tiny
  [Blog]. [[https://www.arducam.com/raspberry-pi-pico-tensorflow-lite-micro-person-detection-arducam/][Online: arducam.com]].

* Footnotes

[fn:3]As I have just learnt, this course (DSC 205) is called
"Introduction to Advanced Data Science" for bureaucratic reasons
having to do with the Lyon college course catalog, but it's going to
be about ML. The other thing I want to spend my money on is
parallelization (this will be a joint project with David Sonnier):
[[https://medium.com/@leerbardon/build-a-diy-supercomputer-a6461b2087d3][building a DIY supercomputer]]!

[fn:2]A gamer told me about another impact of blockchain mining
popularity: she said it had become hard to get hold of GPUs (graphical
processors needed for high gaming performance).

[fn:1]In the same lecture, Ng relates another, more recent definition
of the kind of problem that ML addresses, called a "well-posed problem":
#+begin_quote
A computer is said to /learn/ from experience E with respect to some
task T and some performance measure P, if its performance on T, as
measured by P, improves with experience E.
#+end_quote
In the language of our last lesson, E is the precept, and T could be
any task, no matter how complex, as long as we can define a P.
