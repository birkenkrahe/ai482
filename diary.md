
# Table of Contents

1.  [Thursday, December 16](#orgfbb062b)


<a id="orgfbb062b"></a>

# Thursday, December 16

I'm going to record a short [good-bye video](https://youtu.be/IxyqEW9-12s) later - this is sort of a
transcript for that video. Let me begin by saying that I had an
absolute blast in this class - and I hadn't expected to have one.


## What does it all mean?

Of course I know that AI is hot, perhaps the hottest topic next to
COVID, at the start of this decade, but it's also a field that is
confused about itself.

I still don't know what it all means, but I am a little less
confused about AI, and I hope you are, too! You should know now that
there are many different approaches to AI, including:

-   Sports analytics - using traditional statistics (BI), some
    nifty hardware and embedded systems (IoT)
-   Agents and robotics (soft and hardware)
-   Machine learning - an extension of BI (business intelligence)
    using neural nets as the underlying framework
-   Natural Language Processing - a bit of a hopeless quest because
    of the complexity of language, but still worth pursuing

There were other aspects that we only touched upon briefly.

I wanted to instill in you a critical attitude of the myriad of
promises made often by people without a clue, or by people who are
too full of themselves.

Take this as a recent example: [7 lessons learned from the Vatican's
artificial intelligence symposium](https://www.ncronline.org/news/opinion/7-lessons-learned-vaticans-artificial-intelligence-symposium) (Keegan, 2-Nov-2021). When
reading this (and many similar articles), and checking every sentence and
every claim for true evidence and likelihood, I am left with a
snake-oil impression. Not because AI isn't real but because it is
so relentlessly oversold. I have a bag full of personal opinions
why this is so, and I won't bore you with them now.

Most importantly, don't mistake critical thinking for negative or
pessimistic. You got to know me: I am really optimistic about
technology in general, and computing and AI in particular, but I am
allergic against snake oil salesmen.

Regrettably, the gap between those who know (even a little) about
AI and those who don't, is quickly widening and turning into a
gulf. When it becomes too wide, things will get ugly.

You're among those who know a little more than average now, or
perhaps a lot more (depending whom you talk to), and I hope you can
grow this knowledge further and make good use of it for everyone's
(and your personal) benefit!


## What next?

[On the agenda](https://github.com/birkenkrahe/ai482/blob/main/agenda.md#week-17---goodbye-video), I have listed a few more links that I've come across
recently, and that I'll check out - applications of NLP are my
special interest, but there is also a lot happening in the area of
low-code and no-code<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>, which may alter the practice of
computer science. There's also a photo of a beautiful palace in
Rome. Don't forget the past!

There is, of course, a deluge of links and material, and it's not
going to get better.

Which is why my main advice on "what next" is:

1.  learn to read more, and faster (while developing your critical
    faculties, which will speed you up). Here are the [textbooks](https://github.com/birkenkrahe/org/blob/master/booklist.md) that
    I intend to read (not just, but also for course development).
2.  Talk to other people often about AI - what they think, what they
    want, what they know - and follow up on these
    discussions. I'll be listening to Lex Fridman's podcasts.
3.  Play around with apps and platforms and code as much as you
    can.

This is very general advice, I know, but it is more relevant for AI
than, say, for accounting, or even for many other CS sub-fields.


## The Way of the Course

As I told you at the start, the course topic itself was suggested
to, and not chosen freely by me, which is why I had some
concerns. Once we had started, the concept of lecture + discussion +
presentation + (agile) research project seemed to work out though.

I was impressed with most of your projects - not just the final
presentations, but more so the building up of your competence, and
the series of presentations. I noticed our discussions and your
input getting more interesting every week.

On that note: thanks everyone for the evaluations! 80% response
rate is massive!  Someone found the the "presentations
stressful". I hope you weren't stressed too much - but if you feel
you were, rest assured that presenting frequently, not always
perfectly prepared (or even forced to) is an essential part of your
professional training.

You should not just learn to code but also to read, write and
present. Or if you already know how to, get better at it by doing
more of it.


## Follow-up courses

AI methods will inform most of my own teaching at Lyon. Currently
planned courses of special relevance:

1.  Introduction to advanced data science (DSC 205) - Spring 2022
2.  Data science special topics (DSC 482) - Fall 2022
3.  Machine learning (DSC 305) - Spring 2023

(1,3) will involve a lot of coding and practice, while (2) will
likely be another seminar with more discussion/presentation,
perhaps even a research-based essay.   


## Final words

Again, thank you from the bottom of my heart for welcoming me to
Lyon by working with me during this last term. I wish you a Merry
Christmas, a restful break, and I'm looking forward to seeing some
of you again next term!


# Footnotes

<sup><a id="fn.1" href="#fnr.1">1</a></sup> As I said a few times in class, low-code and no-code means that
AI (and coding) knowledge is more, not less important, because it'll
become increasingly harder to check and debug code - something that's
not changed in principle with the arrival of checking agents that
debug and check automatically. Quite the opposite, because bugs are
not a stochastic show.
